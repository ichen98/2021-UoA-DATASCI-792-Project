---
title: "Auckland Rugby Project - Trend Analysis of GPS Data"
author: "Ian Chen"
date: "30/07/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r tidyverse, cache=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
```

First, I load the datasets in. The 2018 data notably has many more variables than the other years' data. These additional variables may be of use for the analysis, but because there is less data on these variables, they may necessitate a separate model that trains on only the 2018 data.

```{r loading the datasets, cache=TRUE}
# Loading the 2018 .csv files in
master2018 <- 
  list.files(path = "./2018_csvs/", pattern = "*.CSV", full.names = T) %>% 
  map_df(~read.csv(., skip = 4, header = TRUE))

master2019 <- 
  list.files(path = "./2019_csvs/", pattern = "*.CSV", full.names = T) %>% 
  map_df(~read.csv(., skip = 4, header = TRUE, colClasses = rep("character", 17)))

master2020 <- 
  list.files(path = "./2020_csvs/", pattern = "*.CSV", full.names = T) %>% 
  map_df(~read.csv(., skip = 4, header = TRUE))
# Getting the variable classes
varclasses <- unlist(lapply(master2018, class))
```

I begin with cleaning the 2018 .csv files.

The column names have varying degrees of spacing before and after words. They are cleaned up to have consistent names in proper English.

```{r cleaning up column names, cache=TRUE}
# Cleaning up column names
correctColumnNames <- c("Athlete", 
                        "Team", 
                        "Date", 
                        "Start Time", 
                        "Duration Total", 
                        "Duration Speed Hi-Inten", 
                        "Duration HR Hi-Inten", 
                        "Distance Total", 
                        "Distance Rate (m/min)", 
                        "Distance Speed Hi-Inten", 
                        "Distance HR Hi-Inten", 
                        "Speed Max (km/h)", 
                        "Sprints Total", 
                        "Sprints Hi-Inten", 
                        "Sprints HR Hi-Inten", 
                        "HR Max Total (bpm)", 
                        "% Max HR", 
                        "Work Recovery Ratio", 
                        "Speed Duration Total", 
                        "HR Duration Total", 
                        "Athlete Load", 
                        "Metabolic PowerPeak", 
                        "Hi Int Acceleration", 
                        "Hi Int Deceleration", 
                        "Impact Rate (imp/min)", 
                        "Body Impacts", 
                        "Hi Intensity Effort", 
                        "HIE Rate", 
                        "Distance Speed Zone 1", 
                        "Distance Speed Zone 2", 
                        "Distance Speed Zone 3", 
                        "Distance Speed Zone 4", 
                        "Distance Speed Zone 5", 
                        "Sprints Speed Zone 3", 
                        "Sprints Speed Zone 4", 
                        "Sprints Speed Zone 5", 
                        "Duration HR Zone 4", 
                        "Duration HR Zone 5", 
                        "Accelerations Zone 3", 
                        "Accelerations Zone 4", 
                        "Accelerations Zone 5", 
                        "Decelerations Zone 3", 
                        "Decelerations Zone 4", 
                        "Decelerations Zone 5", 
                        "Body Impacts in Body Impacts Zone Total",
                        "Body Impacts Grade 1", 
                        "Body Impacts Grade 2", 
                        "Body Impacts Grade 3", 
                        "Body Impacts Grade 4", 
                        "Body Impacts Grade 5")
colnames(master2018) <- correctColumnNames
```

Each individual .csv includes four opening rows that do not provide any meaningful information (which are skipped when the .csv is read into R), and three rows at the end that provide details about the average (mean), maximum and minimum values for each column. These are not useful for this analysis, so they should be removed here.

Furthermore, there are many data points that have missing data (represented by two asterisks - "**"). These need to be converted into NA values, which are easier to work around than a string of two asterisks forcing numeric columns into character columns.

```{r removing excess rows and converting missing values, cache=TRUE}
# Removing excess rows
master2018 <- subset(master2018, Athlete != "Avg" & Athlete != "Highest" & Athlete != "Lowest")

# Replacing all missing values with NA
master2018 <- na_if(master2018, "**")
```

The cells that were initially occupied by "**" strings forcibly converted their respective columns into character columns during the dataset import. These columns need to be converted into their proper class such that they can be useful for modeling.

First, the dates are imported into R as characters. For ease of reading, the data frame is sorted by date, from earliest to latest. This involves the conversion of the `Date` column into Date class objects, which requires all values in the `Date` column to be of a certain format.

The last column appears to be an error, not existing in the actual .csv files, so it is additionally dropped.

```{r conversion into proper classes, cache=TRUE}
# Converting dates into something usable
library(lubridate)
master2018$Date[21:38] <- "27/10/2018"
master2018$Date <- parse_date_time(master2018$Date, c("%d/%m/%Y"))
# Sorting by date, dropping redundant column `X`
master2018 <- master2018[order(as.Date(master2018$Date)), -51]
```

Columns 11 and 15 (`Distance HR Hi-Inten` and `Sprints HR Hi-Inten` respectively) are numeric values that were also imported into R as characters. These are transformed back into numeric variables. This is necessary for the proportional standardisation that is applied later.

```{r conversion into proper classes 2, cache=TRUE}
# Converting columns 11 and 15 back into numeric vectors
for (i in c(11, 15)) {
  master2018[, i] <- as.numeric(master2018[, i])
}
```

All durations are imported into R as character strings, as R can't parse the "MM:SS" format. Some preprocessing will need to be done with the times in the dataset, and by converting them into numeric values, manipulation of them will become a lot simpler. Therefore, all times in the data are converted to numeric values.

In this case, converting them to seconds is an easy way of standardising all of the times, making them integers. Integers make things easy to calculate without having to deal with fractions of a minute (which are in base 60).

```{r converting the times to seconds, cache=TRUE}
minsec_to_sec <- function(strvec) {
  # All durations are in "MM:SS" format; durations > 1 hr simply have MM > 59
  prelength <- ifelse(nchar(strvec) == 6, 3, ifelse(nchar(strvec) == 5, 2, 1))
  pre <- as.numeric(substr(strvec, 1, prelength))
  suf <- as.numeric(substr(strvec, nchar(strvec) - 1, nchar(strvec)))
  strvec <- pre * 60 + suf
  return(strvec)
}
master2018[, c(5:7, 19:20, 37:38)] <- lapply(master2018[, c(5:7, 19:20, 37:38)], minsec_to_sec)
```

A rugby union match goes for two 40-minute halves, with a halftime of a maximum length of 15 minutes. This sets a match at roughly a maximum of 95 minutes long. In the Mitre 10 Cup, should a semi-final or final match be tied at the end of regulation time, two 10-minute halves of extra time are played. This is the longest extension a Mitre 10 Cup game can have. Because much of the data's time values are abnormally high, a hard limit is set at 95 minutes (roughly the length of a regular match, including halftime), with the exception of the 2018 final, which went to extra time (resulting in a total of 120 minutes being played, so a hard limit of 120 minutes will be applied exclusively for that match).

95 minutes is equal to $95 \times 60 = 5700$ seconds, while 120 minutes is equal to $120 \times 60 = 7200$ seconds, so 5700 and 7200 will be the hard limits imposed on the minutes played.

Other duration variables may also have abnormally high values, so they will need to be adjusted too. These anomalous values are likely due to errors with the time tracking device, as it appears that many of the duration values are problematic.

If a player's total minutes played is cut down to the set ceiling, then the other duration variables are adjusted by calculating a proportion of the original minutes played, and using this proportion as a multiplier for the other duration variables. For instance, if a player has 100 minutes (6000 seconds) played in a non-2018-final match, that player's corresponding proportion is $5700/6000 = 0.95$, which then multiplies by the player's other duration values to give their adjusted values.

```{r adjusting the duration values, cache=TRUE}
# Calculating proportion by the above method
master2018$Proportion <- ifelse(
  as.character(master2018[, 3]) == "2018-10-27", 
  7200 / master2018$`Duration Total`, 
  5700 / master2018$`Duration Total`)
# Only interested in adjusting values that have a `Proportion` value < 1
master2018$Proportion[which(master2018$Proportion > 1)] <- 1
for (j in c(5, 7:8, 10:11, 13:15, 19:24, 26:27, 29:50)) {
  master2018[, j] <- master2018[, j] * master2018$Proportion
}
```

Column 17, `% MaxHR`, contains a percentage symbol in each of the values. Because all of these values should be numeric, the percentage symbol is removed and `% MaxHR` is converted to numeric.

```{r removing percentage symbols, cache=TRUE}
# Removing percentage symbols
master2018[, 17] <- as.numeric(substr(master2018[, 17], 1, nchar(master2018[, 17]) - 1))
```

Column 18, `Work Recovery Ratio`, contains a small set of unique values. This can be recoded into a factor.

```{r recoding work recovery ratio, cache=TRUE}
# Recoding Work Recovery Ratio into a factor
master2018[, 18] <- as.factor(master2018[, 18])
```

Player names are misspelled in different ways across each dataset. These must be standardised to allow for simpler merging of additional information.

```{r standardising names, cache=TRUE}
# Every name from every dataset combined
currentNames <- sort(unique(c(master2018$Athlete, master2019$Athlete, master2020$Athlete)))

# The incorrectly-recorded names
problematicNames <- c("Able, Rob", 
                      "Hallem Ewes, Liam", 
                      "Hodgmen, Alex", 
                      "Lemalu, Faatungu", 
                      "Liaana, Desma", 
                      "Liana, Desma", 
                      "Lundenmuth, Ezeikeil", 
                      "Reidler Kapa, Waimana", 
                      "Ruru, Jonathon", 
                      "Schwenke, Lief", 
                      "Scraffton, Scott", 
                      "Sosene, Mike", 
                      "Sotutu, Hoksins")
# The corrections to the above names
correctedNames <- c("Abel, Robbie", 
                    "Hallam-Eames, Liam", 
                    "Hodgman, Alex", 
                    "Lemalu, Fa'atiga", 
                    "Liaina, Desma", 
                    "Liaina, Desma", 
                    "Lindenmuth, Ezi", 
                    "Riedlinger-Kapa, Waimana", 
                    "Ruru, Jonathan", 
                    "Schwenke, Leif", 
                    "Scrafton, Scott", 
                    "Sosene-Feagai, Mike", 
                    "Sotutu, Hoskins")

# A function for name correction
nameCorrection <- function(data) {
  for (k in 1:length(problematicNames)) {
    data[which(data[, 1] == problematicNames[k]), 1] <- correctedNames[k]
  }
  return(data)
}

# Applying the function
master2018 <- nameCorrection(master2018)
```

Win margins will be used as a one-size-fits-all metric for measuring how good a player's performance in a match is i.e. the response variable for any fitted model. This is added to the main dataset.

```{r match win margin data, cache=TRUE}
# Dates of matches
matchDates <- as.Date(c("2018-08-18", 
                        "2018-08-26", 
                        "2018-08-30", 
                        "2018-09-07", 
                        "2018-09-16", 
                        "2018-09-22", 
                        "2018-09-28", 
                        "2018-10-04", 
                        "2018-10-10", 
                        "2018-10-14", 
                        "2018-10-20", 
                        "2018-10-27", 
                        "2019-08-09", 
                        "2019-08-15", 
                        "2019-08-24", 
                        "2019-08-31", 
                        "2019-09-08", 
                        "2019-09-14", 
                        "2019-09-22", 
                        "2019-09-27", 
                        "2019-10-05", 
                        "2019-10-11", 
                        "2019-10-19", 
                        "2020-09-12", 
                        "2020-09-20", 
                        "2020-09-27", 
                        "2020-10-02", 
                        "2020-10-10", 
                        "2020-10-17", 
                        "2020-10-24", 
                        "2020-10-31", 
                        "2020-11-07", 
                        "2020-11-15", 
                        "2020-11-21", 
                        "2020-11-28"))
# Match win margins by date
margins <- c(4, 16, 18, 26, 5, 1, -5, 5, 48, 16, 21, 7, 
             0, 33, 6, 0, -10, 15, -19, -40, 57, 24, -9, 
             32, -18, 38, 4, 1, 21, -1, 21, 4, -1, 5, -1)
# Combining date and win margins into one dataframe
winMargins <- data.frame(Date = matchDates, margins)
# Combining win margins into the main dataframe, merging by Date
master2018 <- left_join(master2018, winMargins)
```

I created two supplementary files to provide additional necessary variables. The first is `positional_data_by_match.csv`, which contains each match's game day squad. This provides the position that each player named in the squad for that matchup played at. The replacements (wearing jerseys 16-23) were labelled as 16, as the replacement jersey number does not provide exact positional information.

The second supplementary file is `positional data.csv`, which contains the preferred position for each player. This was determined by selecting the position in the starting XV that they appeared in the most over the matches represented in the dataset. For those that did not make any appearances in the starting XV, some Googling and some clarification with Paul Downes, my Auckland Rugby representative filled in their preferred position.

The positional data in `positional_data_by_match.csv` is added to the master dataset for the players that were named in the starting XV for each of the matches played in 2018. The preferred positions in `positional data.csv` is added to the master dataset for any players that were named as replacements, to show what position they would typically fill in if they had started the match with the starting XV.

```{r positional data by match, cache=TRUE}
# Positional data by match
matchPos <- read.csv("positional_data_by_match.csv", skip = 4)
# Rename columns to be consistent with the data
colnames(matchPos) <- c("Athlete", as.character(matchDates))
matchPos <- nameCorrection(matchPos)
# Initialise the position column
master2018$Position <- 0
# Go through each match day
for (l in 2:36) {
  currentDate <- colnames(matchPos)[l]
  # Get the squad that played on/was named for this day
  activeSquad <- matchPos[which(matchPos[, l] != 0), c(1, l)]
  playersOnThisDate <- which(master2018$Date == as.Date(currentDate) & master2018$Athlete %in% activeSquad[, 1])
  # Add the position for each player
  for (m in playersOnThisDate) {
    player <- which(activeSquad[, 1] == master2018[m, 1])
    master2018[m, 53] <- activeSquad[player, 2]
  }
}

# Now to deal with the replacements, which are all labelled 16
# The preferred positions are in "positional data.csv"
preferredPos <- read.csv("positional data.csv")[1:65, ]
colnames(preferredPos) <- c("Name", 
                            "1 - Loosehead prop", 
                            "2 - Hooker", 
                            "3 - Tighthead prop", 
                            "4 - Left lock", 
                            "5 - Right lock", 
                            "6 - Blindside flanker", 
                            "7 - Openside flanker", 
                            "8 - Number 8", 
                            "9 - Scrum-half", 
                            "10 - Fly-half", 
                            "11 - Left wing", 
                            "12 - Inside centre", 
                            "13 - Outside centre", 
                            "14 - Right wing", 
                            "15 - Fullback", 
                            "16-23 - Replacement", 
                            "Pref. pos. (number)", 
                            "Pref. pos. (text)", 
                            "Pref. group")
preferredPos <- nameCorrection(preferredPos)
# Coercing the columns of the preferred positional data into ideal classes
for (n in 2:18) {
  preferredPos[, n] <- as.numeric(preferredPos[, n])
}
# Getting the rows that correspond to replacements
replacements <- which(master2018$Position == 16)
# Giving the replacements their preferred position
for (o in replacements) {
  replacementName <- master2018[o, 1]
  master2018[o, 53] <- as.numeric(preferredPos[which(preferredPos[, 1] == replacementName), 18])
}
# Converting the positional data into a factor
master2018[, 53] <- as.factor(master2018[, 53])
```

Finally, excess rows are removed from the master dataset. These include rows where, for a given match, a player is listed multiple times, as well as players who are in the data but were not named to the 23-man match-day squad for that match. For the latter, they did not contribute to the win margin that corresponds to that match, so their data is not useful for prediction.

```{r removing excess rows, cache=TRUE}
# Removing duplicate rows
for (p in unique(master2018$Date)) {
  matchPlayers <- master2018[which(master2018$Date == p), 1]
  for (q in matchPlayers[duplicated(matchPlayers)]) {
    dupes <- master2018[which(master2018$Date == p & master2018$Athlete == q),]
    notHighestMinutes <- as.numeric(rownames(dupes[which(dupes$`Duration Total` != max(dupes$`Duration Total`)), ]))
    master2018 <- master2018[-notHighestMinutes,]
  }
}
# Deleting players that didn't play in the game, since there would be no win margin associated with their stats
master2018 <- master2018[-which(master2018$Position == 0),]
```

That should be all the preliminary cleaning and preprocessing that needs to be done. The same methods are applied to the 2019 data, although in a modified manner. The 2019 data has a far smaller subset of the variables in the 2018 data, so the column names here are different than the 2018 columns. Otherwise, the same cleaning is applied to the 2019 data, to keep the data consistent across each year.

```{r 2019, cache=TRUE}
# 2019 and 2020 datasets have fewer variables
colnames2019_20 <- c("Athlete", 
                    "Team", 
                    "Date", 
                    "Start Time", 
                    "Duration Total", 
                    "Distance Total", 
                    "Speed Max (km/h)", 
                    "Hi Int Acceleration", 
                    "Distance Speed Zone 1", 
                    "Distance Speed Zone 2", 
                    "Distance Speed Zone 3", 
                    "Distance Speed Zone 4", 
                    "Distance Speed Zone 5", 
                    "Body Impacts in Body Impacts Zone Total", 
                    "Sprints Speed Zone 3", 
                    "Sprints Speed Zone 4", 
                    "Sprints Speed Zone 5")
colnames(master2019) <- colnames2019_20

master2019 <- subset(master2019, Athlete != "Avg" & Athlete != "Highest" & Athlete != "Lowest")
master2019 <- na_if(master2019, "**")

master2019$Date <- parse_date_time(master2019$Date, c("%d/%m/%Y"))
master2019 <- master2019[order(as.Date(master2019$Date)), -18]

for (i in 6:17) {
  master2019[, i] <- as.numeric(master2019[, i])
}

master2019[, 5] <- minsec_to_sec(master2019[, 5])

master2019$Proportion <- 5700 / master2019$`Duration Total`
master2019$Proportion[which(master2019$Proportion > 1)] <- 1
for (j in c(5:6, 8:17)) {
  master2019[, j] <- master2019[, j] * master2019$Proportion
}

master2019 <- nameCorrection(master2019) %>% 
  left_join(winMargins)

master2019$Position <- 0
for (l in 2:36) {
  currentDate <- colnames(matchPos)[l]
  activeSquad <- matchPos[which(matchPos[, l] != 0), c(1, l)]
  playersOnThisDate <- which(master2019$Date == as.Date(currentDate) & master2019$Athlete %in% activeSquad[, 1])
  for (m in playersOnThisDate) {
    player <- which(activeSquad[, 1] == master2019[m, 1])
    master2019[m, 20] <- activeSquad[player, 2]
  }
}
replacements <- which(master2019$Position == 16)
for (o in replacements) {
  replacementName <- master2019[o, 1]
  master2019[o, 20] <- as.numeric(preferredPos[which(preferredPos[, 1] == replacementName), 18])
}
master2019[, 20] <- as.factor(master2019[, 20])

for (p in unique(master2019$Date)) {
  matchPlayers <- master2019[which(master2019$Date == p), 1]
  for (q in matchPlayers[duplicated(matchPlayers)]) {
    dupes <- master2019[which(master2019$Date == p & master2019$Athlete == q),]
    notHighestMinutes <- as.numeric(rownames(dupes[which(dupes$`Duration Total` != max(dupes$`Duration Total`)), ]))
    master2019 <- master2019[-notHighestMinutes,]
  }
}
master2019 <- master2019[-which(master2019$Position == 0),]
```

The same is done with the 2020 dataset, which closely resembles the 2019 dataset in structure and format, including the number and name of columns.

```{r 2020, cache=TRUE}
colnames(master2020) <- colnames2019_20

master2020 <- subset(master2020, Athlete != "Avg" & Athlete != "Highest" & Athlete != "Lowest")
master2020 <- na_if(master2020, "**")

master2020$Date <- parse_date_time(master2020$Date, c("%d/%m/%Y"))
master2020 <- master2020[order(as.Date(master2020$Date)), -18]

for (i in 6:17) {
  master2020[, i] <- as.numeric(master2020[, i])
}

master2020[, 5] <- minsec_to_sec(master2020[, 5])

master2020$Proportion <- 5700 / master2020$`Duration Total`
master2020$Proportion[which(master2020$Proportion > 1)] <- 1
for (j in c(5:6, 8:17)) {
  master2020[, j] <- master2020[, j] * master2020$Proportion
}

master2020 <- nameCorrection(master2020) %>% 
  left_join(winMargins)

master2020$Position <- 0
for (l in 2:36) {
  currentDate <- colnames(matchPos)[l]
  activeSquad <- matchPos[which(matchPos[, l] != 0), c(1, l)]
  playersOnThisDate <- which(master2020$Date == as.Date(currentDate) & master2020$Athlete %in% activeSquad[, 1])
  for (m in playersOnThisDate) {
    player <- which(activeSquad[, 1] == master2020[m, 1])
    master2020[m, 20] <- activeSquad[player, 2]
  }
}
replacements <- which(master2020$Position == 16)
for (o in replacements) {
  replacementName <- master2020[o, 1]
  master2020[o, 20] <- as.numeric(preferredPos[which(preferredPos[, 1] == replacementName), 18])
}
master2020[, 20] <- as.factor(master2020[, 20])

for (p in unique(master2020$Date)) {
  matchPlayers <- master2020[which(master2020$Date == p), 1]
  for (q in matchPlayers[duplicated(matchPlayers)]) {
    dupes <- master2020[which(master2020$Date == p & master2020$Athlete == q),]
    notHighestMinutes <- as.numeric(rownames(dupes[which(dupes$`Duration Total` != max(dupes$`Duration Total`)), ]))
    master2020 <- master2020[-notHighestMinutes,]
  }
}
master2020 <- master2020[-which(master2020$Position == 0),]
```

Finally, the 2019 and 2020 datasets are combined, since they share the same columns. The 2018 dataset is joined with them also, but only at the columns that are shared with the 2019 and 2020 datasets.

```{r combining the datasets, cache=TRUE}
combinedData <- rbind(master2018[, c(1:5, 8, 12, 23, 29:36, 45, 51:53)], master2019, master2020)
```

# Finding the positional maximum, minimum and mean data for each marker

The 2018 dataset contains 53 variables, 33 of which are not shared by the 2019 and 2020 datasets. Within the 20 variables that are shared, 7 of them are not performance markers; they are either redundant information, unique identifiers for each individual row, or variables I created during the cleaning process.

Therefore, the 2018 dataset must be separated by position, and then the positional maximum, minimum and mean can be found. These values are printed. Variable 18, `HIE Rate` is not numeric, so it is left out here. Any performance markers that are shared by the 2018, 2019 and 2020 datasets are then found and printed afterwards.

```{r positional 2018, cache=TRUE}
for (r in 1:15) {
  # Finding the positional minimum, mean and maximum for performance markers exclusive to the 2018 dataset
  positionalData <- master2018[which(master2018$Position == r),]
  cat(paste0("POSITION: ", as.character(r)), "\n")
  for (s in c(6:7, 9:11, 13:17, 19:22, 24:28, 37:44, 46:50)) {
    print(paste0("Variable ", as.character(s), " - ", colnames(positionalData)[s], 
                 " - MIN: ", min(positionalData[, s], na.rm = TRUE), 
                 " | MEAN: ", mean(positionalData[, s], na.rm = TRUE), 
                 " | MAX: ", max(positionalData[, s], na.rm = TRUE)))
  }
  cat("\n")
  # Finding the positional minimum, mean and maximum for performance markers shared between the 2018, 2019 and 2020 datasets
  positionalSmallData <- combinedData[which(combinedData$Position == r),]
  for (t in c(5:17)) {
    print(paste0("Variable ", as.character(t), " - ", colnames(positionalSmallData)[t], 
                 " - MIN: ", min(positionalSmallData[, t], na.rm = TRUE), 
                 " | MEAN: ", mean(positionalSmallData[, t], na.rm = TRUE), 
                 " | MAX: ", max(positionalSmallData[, t], na.rm = TRUE)))
  }
  cat("\n", "\n", "\n")
}

# TODO Maybe give the variables units (specifically the ones transformed in the standardisation by proportion process)? Just so it makes sense to read
```


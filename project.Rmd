---
title: "Auckland Rugby Project - Trend Analysis of GPS Data"
author: "Ian Chen"
date: "30/07/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r tidyverse, cache=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
```

First, I load the datasets in. I begin with the 2018 .csv files. The 2018 data notably has many more variables than the other years' data. These additional variables may be of use for the analysis, but because there is less data on these variables, they may necessitate a separate model that trains on only the 2018 data.

```{r loading the datasets, cache=TRUE}
# Loading the 2018 .csv files in
master2018 <- 
  list.files(path = "./2018_csvs/", pattern = "*.CSV", full.names = T) %>% 
  map_df(~read.csv(., skip = 4, header = TRUE))
# Getting the variable classes
varclasses <- unlist(lapply(master2018, class))
```

The column names have varying degrees of spacing before and after words. They are cleaned up to have consistent names in proper English.

```{r cleaning up column names, cache=TRUE}
# Cleaning up column names
correctColumnNames <- c("Athlete", 
                        "Team", 
                        "Date", 
                        "Start Time", 
                        "Duration Total", 
                        "Duration Speed Hi-Inten", 
                        "Duration HR Hi-Inten", 
                        "Distance Total", 
                        "Distance Rate (m/min)", 
                        "Distance Speed Hi-Inten", 
                        "Distance HR Hi-Inten", 
                        "Speed Max (km/h)", 
                        "Sprints Total", 
                        "Sprints Hi-Inten", 
                        "Sprints HR Hi-Inten", 
                        "HR Max Total (bpm)", 
                        "% Max HR", 
                        "Work Recovery Ratio", 
                        "Speed Duration Total", 
                        "HR Duration Total", 
                        "Athlete Load", 
                        "Metabolic PowerPeak", 
                        "Hi Int Acceleration", 
                        "Hi Int Deceleration", 
                        "Impact Rate (imp/min)", 
                        "Body Impacts", 
                        "Hi Intensity Effort", 
                        "HIE Rate", 
                        "Distance Speed Zone 1", 
                        "Distance Speed Zone 2", 
                        "Distance Speed Zone 3", 
                        "Distance Speed Zone 4", 
                        "Distance Speed Zone 5", 
                        "Sprints Speed Zone 3", 
                        "Sprints Speed Zone 4", 
                        "Sprints Speed Zone 5", 
                        "Duration HR Zone 4", 
                        "Duration HR Zone 5", 
                        "Accelerations Zone 3", 
                        "Accelerations Zone 4", 
                        "Accelerations Zone 5", 
                        "Decelerations Zone 3", 
                        "Decelerations Zone 4", 
                        "Decelerations Zone 5", 
                        "Body Impacts in Body Impacts Zone Total",
                        "Body Impacts Grade 1", 
                        "Body Impacts Grade 2", 
                        "Body Impacts Grade 3", 
                        "Body Impacts Grade 4", 
                        "Body Impacts Grade 5")
colnames(master2018) <- correctColumnNames
```

Each individual .csv includes four opening rows that do not provide any meaningful information (which are skipped when the .csv is read into R), and three rows at the end that provide details about the average (mean), maximum and minimum values for each column. These are not useful for this analysis, so they should be removed here.

Furthermore, there are many data points that have missing data (represented by two asterisks - "**"). These need to be converted into NA values, which are easier to work around than a string of two asterisks forcing numeric columns into character columns.

```{r removing excess rows and converting missing values, cache=TRUE}
# Removing excess rows
master2018 <- subset(master2018, Athlete != "Avg" & Athlete != "Highest" & Athlete != "Lowest")

# Replacing all missing values with NA
master2018 <- na_if(master2018, "**")
```

The cells that were initially occupied by "**" strings forcibly converted their respective columns into character columns during the dataset import. These columns need to be converted into their proper class such that they can be useful for modeling.

First, the dates are imported into R as characters. For ease of reading, the data frame is sorted by date, from earliest to latest. This involves the conversion of the `Date` column into Date class objects, which requires all values in the `Date` column to be of a certain format.

The last column appears to be an error, not existing in the actual .csv files, so it is additionally dropped.

```{r conversion into proper classes, cache=TRUE}
# Converting dates into something usable
library(lubridate)
master2018$Date[21:38] <- "27/10/2018"
master2018$Date <- parse_date_time(master2018$Date, c("%d/%m/%Y"))
# Sorting by date, dropping redundant column `X`
master2018 <- master2018[order(as.Date(master2018$Date)), -51]
```

Columns 11 and 15 (`Distance HR Hi-Inten` and `Sprints HR Hi-Inten` respectively) are numeric values that were also imported into R as characters. These are transformed back into numeric variables. This is necessary for the proportional standardisation that is applied later.

```{r conversion into proper classes 2, cache=TRUE}
# Converting columns 11 and 15 back into numeric vectors
for (i in c(11, 15)) {
  master2018[, i] <- as.numeric(master2018[, i])
}
```

All durations are imported into R as character strings, as R can't parse the "MM:SS" format. Some preprocessing will need to be done with the times in the dataset, and by converting them into numeric values, manipulation of them will become a lot simpler. Therefore, all times in the data are converted to numeric values.

In this case, converting them to seconds is an easy way of standardising all of the times, making them integers. Integers make things easy to calculate without having to deal with fractions of a minute (which are in base 60).

```{r converting the times to seconds, cache=TRUE}
minsec_to_sec <- function(strvec) {
  # All durations are in "MM:SS" format; durations > 1 hr simply have MM > 59
  prelength <- ifelse(nchar(strvec) == 6, 3, ifelse(nchar(strvec) == 5, 2, 1))
  pre <- as.numeric(substr(strvec, 1, prelength))
  suf <- as.numeric(substr(strvec, nchar(strvec) - 1, nchar(strvec)))
  strvec <- pre * 60 + suf
  return(strvec)
}
master2018[, c(5:7, 19:20, 37:38)] <- lapply(master2018[, c(5:7, 19:20, 37:38)], minsec_to_sec)
```

A rugby union match goes for two 40-minute halves, with a halftime of a maximum length of 15 minutes. This sets a match at roughly a maximum of 95 minutes long. In the Mitre 10 Cup, should a semi-final or final match be tied at the end of regulation time, two 10-minute halves of extra time are played. This is the longest extension a Mitre 10 Cup game can have. Because much of the data's time values are abnormally high, a hard limit is set at 95 minutes (roughly the length of a regular match, including halftime), with the exception of the 2018 final, which went to extra time (resulting in a total of 120 minutes being played, so a hard limit of 120 minutes will be applied exclusively for that match).

95 minutes is equal to $95 \times 60 = 5700$ seconds, while 120 minutes is equal to $120 \times 60 = 7200$ seconds, so 5700 and 7200 will be the hard limits imposed on the minutes played.

Other duration variables may also have abnormally high values, so they will need to be adjusted too. These anomalous values are likely due to errors with the time tracking device, as it appears that many of the duration values are problematic.

If a player's total minutes played is cut down to the set ceiling, then the other duration variables are adjusted by calculating a proportion of the original minutes played, and using this proportion as a multiplier for the other duration variables. For instance, if a player has 100 minutes (6000 seconds) played in a non-2018-final match, that player's corresponding proportion is $5700/6000 = 0.95$, which then multiplies by the player's other duration values to give their adjusted values.

```{r adjusting the duration values, cache=TRUE}
# Calculating proportion by the above method
master2018$Proportion <- ifelse(
  as.character(master2018[, 3]) == "2018-10-27", 
  7200 / master2018$`Duration Total`, 
  5700 / master2018$`Duration Total`)
# Only interested in adjusting values that have a `Proportion` value < 1
master2018$Proportion[which(master2018$Proportion > 1)] <- 1
for (j in c(5, 7:8, 10:11, 13:15, 19:24, 26:27, 29:50)) {
  master2018[, j] <- master2018[, j] * master2018$Proportion
}
```

Column 17, `% MaxHR`, contains a percentage symbol in each of the values. Because all of these values should be numeric, the percentage symbol is removed and `% MaxHR` is converted to numeric.

```{r removing percentage symbols, cache=TRUE}
# Removing percentage symbols
master2018[, 17] <- as.numeric(substr(master2018[, 17], 1, nchar(master2018[, 17]) - 1))
```

Column 18, `Work Recovery Ratio`, contains a small set of unique values. This can be recoded into a factor.

```{r recoding work recovery ratio, cache=TRUE}
# Recoding Work Recovery Ratio into a factor
master2018[, 18] <- as.factor(master2018[, 18])
```



```{r positional and match data, cache=TRUE}
# Dates of matches
matchDates <- as.Date(c("2018-08-18", 
                        "2018-08-26", 
                        "2018-08-30", 
                        "2018-09-07", 
                        "2018-09-16", 
                        "2018-09-22", 
                        "2018-09-28", 
                        "2018-10-04", 
                        "2018-10-10", 
                        "2018-10-14", 
                        "2018-10-20", 
                        "2018-10-27", 
                        "2019-08-09", 
                        "2019-08-15", 
                        "2019-08-24", 
                        "2019-08-31", 
                        "2019-09-08", 
                        "2019-09-14", 
                        "2019-09-22", 
                        "2019-09-27", 
                        "2019-10-05", 
                        "2019-10-11", 
                        "2019-10-19", 
                        "2020-09-12", 
                        "2020-09-20", 
                        "2020-09-27", 
                        "2020-10-02", 
                        "2020-10-10", 
                        "2020-10-17", 
                        "2020-10-24", 
                        "2020-10-31", 
                        "2020-11-07", 
                        "2020-11-15", 
                        "2020-11-21", 
                        "2020-11-28"))
# Match win margins by date
margins <- c(4, 16, 18, 26, 5, 1, -5, 5, 48, 16, 21, 7, 
             0, 33, 6, 0, -10, 15, -19, -40, 57, 24, -9, 
             32, -18, 38, 4, 1, 21, -1, 21, 4, -1, 5, -1)
# Combining date and win margins into one dataframe
winMargins <- data.frame(Date = matchDates, margins)
# Combining win margins into the main dataframe
master2018 <- left_join(master2018, winMargins)


# Positional data by match
matchPos <- read.csv("positional_data_by_match.csv", skip = 4)
# Rename columns to be consistent with the data
colnames(matchPos) <- c("Athlete", as.character(matchDates))
master2018$Position <- 0
for (k in 2:36) {
  currentDate <- colnames(matchPos[, k])
  playersOnThisDate <- which(master2018$Date == as.Date(currentDate))
  activeSquad <- matchPos[which(matchPos[, k] != 0), 1]
  
}
```










```{r loading the rest of the datasets, cache=TRUE}
varclasses <- c()

master2019 <- 
  list.files(path = "./2019_csvs/", pattern = "*.CSV", full.names = T) %>% 
  map_df(~read.csv(., skip = 4, header = TRUE, colClasses = rep("character", 17)))
master2019 <- subset(master2019, Athlete != "Avg" & Athlete != "Highest" & Athlete != "Lowest")
master2019 <- na_if(master2019, "**")

master2020 <- 
  list.files(path = "./2020_csvs/", pattern = "*.CSV", full.names = T) %>% 
  map_df(~read.csv(., skip = 4, header = TRUE))
master2020 <- subset(master2020, Athlete != "Avg" & Athlete != "Highest" & Athlete != "Lowest")
master2020 <- na_if(master2020, "**")
```

